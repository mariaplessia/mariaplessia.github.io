<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Project 1 - MyTorch</title>
    <link rel="stylesheet" href="style.css" />
    <link rel="stylesheet" href="mediaqueries.css" />
  </head>
</head>
<body>
  
  <nav id="desktop-nav">
    <div class="logo">Maria Plessia</div>
      <div>
        <ul class="nav-links">
          <a href="index.html">Main Page</a>
        </ul>
      </div>
  </nav>
  
  <section id="about">
      <h1 class="title">MyTorch</h1>
      <p class="section__text__p1">Implementation of my own custom deep learning library from scratch inspired by PyTorch</p>
      <p><br/><br/><br/><br/></p>

      <h2 class="part-title">Part 1</h2>
      
      <div class="section-container">
        <div class="section__pic-container">
          <img
            src="./assets/p1-p1.png"
            alt="Project 1 part 1 pic"
            class="about-pic"
          />
        </div>
        <div class="about-details-container">
          <div class="about-containers">
            <div class="details-container">
              <h3>Focus</h3>
              <ul>
                <li>Activation Functions</li>
                <li>Loss Functions</li>
                <li>Optimizers</li>
                <li>NN Layers & MLP</li>
                <li>Regularization</li>
              </ul>
            </div>
            <div class="details-container">

              <h3>Learning Outcomes</h3>
              <ul>
                <li>How to implement an MLP from scratch</li>
                <li>How to perform forward inference</li>
                <li>How to implement training of my MLP</li>
                <li>How to implement MSE, CSLoss, backpropagation, SGD</li>
              </ul>
            </div>
          </div>
          
          <div class="text-container">
            <p>
              In this project, I will implement my own deep learning library from scratch.
              Inspired by PyTorch, my library – MyTorch – will be used to create everything from multilayer perceptrons,
              convolutional neural networks, to recurrent neural networks with gated recurrent units (GRU) and long-short
              term memory (LSTM) structures. The goal of Part 1 is to understand forward propagation, loss calculation,
              backward propagation, and gradient descent.
              <br/>
              <br/>
            </p>
            <p>
              Here, I started by creating the core components of multilayer perceptrons: linear layers,
              activations, loss functions, and batch normalization. I implemented these classes in MyTorch. The requirement 
              of this project was to specifically implement the mathematics into the code, and understand how all the
              components are related. I only used numpy and no other python library.
              <br/>
              <br/>
            </p>
            <p>
              In terms of the mathematics, I coded the equations needed to build a simple Neural Network
              Layer. This includes forward and backward propagation for the activations, loss functions, linear layers, and
              batch normalization.
              <br/>
            </p>
          </div>
        </div>
      </div>
      <img
        src="./assets/arrow.png"
        alt="Arrow icon"
        class="icon arrow"
        onclick="location.href='./#details'"
      />
    </section>

    <section>
      
    </section>

</body>
</html>
